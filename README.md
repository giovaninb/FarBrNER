
# Processamento de Linguagem Natural para Reconhecimento de Medicamentos

Este reposit√≥rio cont√©m o c√≥digo de um projeto para identificar medicamentos em anota√ß√µes cl√≠nicas.

O modelo usa a biblioteca Transformers, come√ßando com o [modelo pr√©-treinado BERTimbau](https://github.com/neuralmind-ai/portuguese-bert). 
Finalmente, o refinamento √© realizado em um corpus de notas cl√≠nicas anotadas 
(anotadas usando [doccano](https://github.com/doccano/doccano)).

## Execu√ß√£o

O refinamento pode ser realizado atrav√©s do script *finetune* usando o terminal. 
Este script assume que os dados s√£o um arquivo JSONL de texto anotado exportado 
do doccano (`--datafile example.jsonl`), ou um conjunto de dados HuggingFace salvo.

Se voc√™ executar este script uma vez em um arquivo JSONL de anota√ß√µes, poder√° optar por 
salvar o conjunto de dados em uma pasta (`--save_data_dir "save_path"`) e us√°-lo para 
execu√ß√µes de treinamento subsequentes (`--datafile "save_path"`).

Para o acompanhamento de experimentos, usamos o [Weights and Biases](https://wandb.ai).
Voc√™ poder√° optar habilitar usando o par√¢metro (`--wandb_on`).

```bash
  python .\finetune.py --folds 5 --epochs 15 --lr 5e-5 --wandb_on --hub_off 
  --project 'Example Project' --run_name cross-validation --datafile example.jsonl
```
    
## Como usar o modelo a partir da biblioteca ü§ó/[transformers](https://github.com/huggingface/transformers)

```python
from transformers import AutoTokenizer, AutoModelForTokenClassification

tokenizer = AutoTokenizer.from_pretrained("giggio/FarBrBERT-base")

model = AutoModelForTokenClassification.from_pretrained("giggio/FarBrBERT-base")
```


